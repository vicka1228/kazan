# -*- coding: utf-8 -*-
"""Kazan_Milestone4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w_BdLFL7SmHnHA0-HSNZE9x2gs8lhR6i
"""

# GET
import requests
import urllib
import json
# Spotify login and fetch data
import spotipy
import spotipy.util as util
from spotipy.oauth2 import SpotifyOAuth
# Dataframe and visualization
import pandas as pd
import numpy as np
import datetime
# SQL Database
import sqlite3
from sqlalchemy import create_engine
# Machine Learning Libraries
from sklearn.ensemble import BaggingRegressor
from sklearn.model_selection import train_test_split


# spotify configuration details
SPOTIFY_CLIENT_ID = "d4c88e10069d4bf789bf0d70cb71114a"
SPOTIFY_CLIENT_SECRET = "51dee21966eb485eae0ee1320f731dba"
SCOPE = "user-top-read"
REDIRECT_URI = "http://localhost:8888/callback/"

# database & table configuration details
TABLE = 'CONCERTS'
DATABASE = 'DATABASE'

# user log in â€“ won't work from .ipynb, download as .py and run
# token = util.prompt_for_user_token(scope=SCOPE,client_id=SPOTIFY_CLIENT_ID,client_secret=SPOTIFY_CLIENT_SECRET, redirect_uri=REDIRECT_URI)

# returns user's top n artists
# NOTE: needs token to work
def getTopNArtists(n):
    if token:
        sp = spotipy.Spotify(auth = token)
        top_artists = sp.current_user_top_artists(limit = n, time_range = "medium_term")
    else:
        print("Can't get token!")
    
    artists=[]
    # user's top artists in the past 6 months
    for artist in top_artists["items"]:
        artists.append(artist["name"])
    return artists

def clean_dataframe(df):
  df = pd.read_csv("data.csv")
  df = df[df['minprice'] != 0]
  df = df[df['genre'] != 'Undefined']
  df = df[df['pop'] != 0.0]

  df = df.dropna()
  df.reset_index(inplace = True, drop = True)
  df["pop"].astype(int)

clean_dataframe(pd.read_csv("data.csv"))

def save_to_CSV(df):
  df.to_csv('data2.csv')

save_to_CSV(df)

'''
Saving the dataframe into the SQL
'''

conn = sqlite3.connect(DATABASE)

def save_to_SQL(df):
  c = conn.cursor()
  c.execute('CREATE TABLE IF NOT EXISTS ' + TABLE + ' (artist_name text, min_price number)')
  conn.commit()
  df.to_sql(TABLE, conn, if_exists = 'replace', index = False)

save_to_SQL(df)

'''
Fetching dataframe from SQL
'''

def get_df_from_SQL():
  return pd.read_sql_query("SELECT * FROM " + TABLE, conn)

df = get_df_from_SQL()

'''
Predicting price using Random Forest with bagging
'''

def mean_average_error(y_true, predictions):
    y_true, predictions = np.array(y_true), np.array(predictions)
    return np.mean(np.abs(y_true - predictions))

# returns X and y used for ML
def get_data(df):
  
  # select features from the dataset
  X = df[['weekend', 'score', 'month', 'pop', 'genre', 'artist', 'venue']]

  # encode categorical data
  X = pd.get_dummies(X, columns = ['month', 'genre', 'artist', 'venue'], drop_first=True)

  # create target variable 
  y = df['minprice']

  # convert type to integer
  y = y.astype('int')
  return (X, y)

# split dataframe into train and test
def split(df):
  return train_test_split(*get_data(df), test_size = 0.2, random_state = 0)
          
# predict the min price using Random Forest with bagging
def train_model(X_train, y_train):

  # create model with the most optimal number of estimators
  model = BaggingRegressor(n_estimators = 500)

  # train the model
  model.fit(X_train, y_train)
  
  return model


''' Comment this out'''
# compare algorithms correctness
def print_results(y_test, y_pred):
  print(mean_average_error(y_test, y_pred))
  for y_p, y_t in zip(y_pred, y_test.iteritems()):
    print(round(y_p, 2), y_t[1])

# predict the prices
def predict(model, X_test, y_test):
  y_pred = model.predict(X_test)

  ''' Comment this out'''
  # print_results(y_test, y_pred)
  
  return y_pred

# for _ in range(1):
X_train, X_test, y_train, y_test = split(df)
model = train_model(X_train, y_train)
predict(model, X_test, y_test)

'''
APIs for the frontend
'''

def nparray_tojson(arr):
  return json.dumps(arr.tolist())


# concert lists
def get_concert_list():
  return nparray_tojson(pd.read_sql_query("SELECT venue FROM " + TABLE, conn).venue.unique())

# print(get_concert_list())

# the artists list
def get_artists_list():
  return nparray_tojson(pd.read_sql_query("SELECT artist FROM " + TABLE, conn).artist.unique())

# print(get_artists_list())

# the information about the concert including prices
def get_concert_information(venue):
  return pd.read_sql_query("SELECT * FROM " + TABLE + " WHERE venue = '" + venue + "'", conn).to_json()

# print(get_concert_information('CFSB Center'))

# implement the search algorithm 
def search(search_string):
  for column_name in ['venue', 'artist', 'city', 'showName', 'genre']:
    ans = pd.read_sql_query("SELECT * FROM " + TABLE + " WHERE " + column_name + " LIKE '%" + search_string + "%'", conn)
    if not ans.empty:
      return ans.to_json()

# print(search('Basketball'))

# send concerts of a particular artist (based on search)
def get_concert_of_artist(artist):
  return pd.read_sql_query("SELECT * FROM " + TABLE + " WHERE artist = '" + artist + "'", conn).to_json()

# print(get_concert_of_artist('Drake'))